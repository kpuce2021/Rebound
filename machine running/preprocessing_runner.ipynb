{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from enum import Enum\n",
    "\n",
    "def get_all_subject_ids():#번호 다 가져오는 함수\n",
    "    subjects_as_ints = [3509524, 5132496, 1066528, 5498603, 2638030, 2598705, 5383425, 1455390, 4018081, 9961348,1449548, 8258170, 781756, 9106476, 8686948, 8530312, 3997827, 4314139, 1818471, 4426783, 8173033, 7749105, 5797046, 759667, 8000685, 6220552, 844359, 9618981, 1360686, 46343, 8692923]\n",
    "    subjects_as_strings = []\n",
    "    for subject in subjects_as_ints:\n",
    "        subjects_as_strings.append(str(subject))\n",
    "    return subjects_as_strings\n",
    "\n",
    "def get_project_root() -> Path:\n",
    "    return Path()\n",
    "\n",
    "def get_intersecting_interval(collection_list):\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "    for collection in collection_list:\n",
    "        interval = collection.get_interval()\n",
    "        start_times.append(interval.start_time)\n",
    "        end_times.append(interval.end_time)\n",
    "    return Interval(start_time=max(start_times), end_time=min(end_times))\n",
    "\n",
    "def read_precleaned(subject_id):\n",
    "    psg_path = str(Path().joinpath('labels/' + subject_id + '_labeled_sleep.txt'))\n",
    "    data = []\n",
    "\n",
    "    with open(psg_path, 'rt') as csv_file:\n",
    "        file_reader = csv.reader(csv_file, delimiter=' ', quotechar='|')\n",
    "        count = 0\n",
    "        rows_per_epoch = 1\n",
    "        for row in file_reader:\n",
    "            if count == 0:\n",
    "                start_time = float(row[0])\n",
    "                start_score = int(row[1])\n",
    "                epoch = Epoch(timestamp=start_time, index=1)\n",
    "                data.append(StageItem(epoch=epoch, stage=PSGConverter.get_label_from_int(start_score)))\n",
    "            else:\n",
    "                timestamp = start_time + count * 30\n",
    "                score = int(row[1])\n",
    "                epoch = Epoch(timestamp=timestamp,index=(1 + int(np.floor(count / rows_per_epoch))))\n",
    "\n",
    "                data.append(StageItem(epoch=epoch, stage=PSGConverter.get_label_from_int(score)))\n",
    "            count = count + 1\n",
    "    return PSGRawDataCollection(subject_id=subject_id, data=data)  \n",
    "\n",
    "def remove_repeats(array):\n",
    "    array_no_repeats = np.unique(array, axis=0)\n",
    "    array_no_repeats = array_no_repeats[np.argsort(array_no_repeats[:, 0])]\n",
    "    return array_no_repeats\n",
    "\n",
    "def load(motion_file, delimiter=' '):\n",
    "    motion_array = pd.read_csv(str(motion_file), delimiter=delimiter).values\n",
    "    return motion_array\n",
    "\n",
    "def get_raw_file_path(subject_id):\n",
    "    project_root = get_project_root()\n",
    "    return project_root.joinpath('motion/' + subject_id + '_acceleration.txt')\n",
    "\n",
    "def load_raw(subject_id):\n",
    "    raw_motion_path = get_raw_file_path(subject_id)\n",
    "    motion_array = load(raw_motion_path)\n",
    "    motion_array = remove_repeats(motion_array)\n",
    "    return MotionCollection(subject_id=subject_id, data=motion_array)\n",
    "\n",
    "def crop_all(subject_id):\n",
    "    psg_raw_collection = read_precleaned(subject_id)  # Loads already extracted PSG data\n",
    "    motion_collection = load_raw(subject_id)\n",
    "    \n",
    "    valid_interval = get_intersecting_interval([psg_raw_collection, motion_collection])\n",
    "    psg_raw_collection = PSGService.crop(psg_raw_collection, valid_interval)\n",
    "    motion_collection = MotionService.crop(motion_collection, valid_interval)\n",
    "    PSGService.write(psg_raw_collection)\n",
    "    MotionService.write(motion_collection)\n",
    "    #ActivityCountService.build_activity_counts_without_matlab(subject_id, motion_collection.data)  # Builds activity counts with python, not MATLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interval(object):\n",
    "    def __init__(self, start_time, end_time):\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionCollection(object):\n",
    "    def __init__(self, subject_id, data):\n",
    "        self.subject_id = subject_id\n",
    "        self.data = data\n",
    "        self.timestamps = data[:, 0]\n",
    "        self.values = data[:, 1:]\n",
    "\n",
    "    def get_interval(self):\n",
    "        return Interval(start_time=np.amin(self.data[:, 0]),\n",
    "                        end_time=np.amax(self.data[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepStage(Enum):\n",
    "    wake = 0\n",
    "    n1 = 1\n",
    "    n2 = 2\n",
    "    n3 = 3\n",
    "    n4 = 4\n",
    "    rem = 5\n",
    "    unscored = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSGRawDataCollection(object):\n",
    "    def __init__(self, subject_id, data: [SleepStage]):\n",
    "        self.subject_id = subject_id\n",
    "        self.data = data\n",
    "\n",
    "    def get_np_array(self):\n",
    "        number_of_epochs = len(self.data)\n",
    "        array = np.zeros((number_of_epochs, 2))\n",
    "        for index in range(number_of_epochs):\n",
    "            stage_item = self.data[index]\n",
    "            array[index, 0] = stage_item.epoch.timestamp\n",
    "            array[index, 1] = stage_item.stage.value\n",
    "        return array\n",
    "\n",
    "    def get_interval(self):\n",
    "        number_of_epochs = len(self.data)\n",
    "        min_timestamp = 1e15\n",
    "        max_timestamp = -1\n",
    "        for index in range(number_of_epochs):\n",
    "            stage_item = self.data[index]\n",
    "            if stage_item.epoch.timestamp < min_timestamp:\n",
    "                min_timestamp = stage_item.epoch.timestamp\n",
    "            if stage_item.epoch.timestamp > max_timestamp:\n",
    "                max_timestamp = stage_item.epoch.timestamp\n",
    "        return Interval(start_time=min_timestamp, end_time=max_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StageItem(object):\n",
    "    def __init__(self, epoch, stage: SleepStage):\n",
    "        self.epoch = epoch\n",
    "        self.stage = stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSGConverter(object):\n",
    "    strings_to_labels = {\n",
    "        \"?\": SleepStage.unscored,\n",
    "        \"W\": SleepStage.wake,\n",
    "        \"1\": SleepStage.n1,\n",
    "        \"N1\": SleepStage.n1,\n",
    "        \"2\": SleepStage.n2,\n",
    "        \"N2\": SleepStage.n2,\n",
    "        \"3\": SleepStage.n3,\n",
    "        \"N3\": SleepStage.n3,\n",
    "        \"4\": SleepStage.n4,\n",
    "        \"N4\": SleepStage.n4,\n",
    "        \"R\": SleepStage.rem,\n",
    "        \"M\": SleepStage.wake}\n",
    "\n",
    "    ints_to_labels = {\n",
    "        -1: SleepStage.unscored,\n",
    "        0: SleepStage.wake,\n",
    "        1: SleepStage.n1,\n",
    "        2: SleepStage.n2,\n",
    "        3: SleepStage.n3,\n",
    "        4: SleepStage.n4,\n",
    "        5: SleepStage.rem,\n",
    "        6: SleepStage.unscored}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_from_string(stage_string):\n",
    "        if stage_string in PSGConverter.strings_to_labels:\n",
    "            return PSGConverter.strings_to_labels[stage_string]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_label_from_int(stage_int):\n",
    "        if stage_int in PSGConverter.ints_to_labels:\n",
    "            return PSGConverter.ints_to_labels[stage_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constants(object):\n",
    "    # WAKE_THRESHOLD = 0.3  # These values were used for scikit-learn 0.20.3, See:\n",
    "    # REM_THRESHOLD = 0.35  # https://scikit-learn.org/stable/whats_new.html#version-0-21-0\n",
    "    WAKE_THRESHOLD = 0.5  #\n",
    "    REM_THRESHOLD = 0.35\n",
    "\n",
    "    EPOCH_DURATION_IN_SECONDS = 30\n",
    "    SECONDS_PER_MINUTE = 60\n",
    "    SECONDS_PER_DAY = 3600 * 24\n",
    "    SECONDS_PER_HOUR = 3600\n",
    "    VERBOSE = False\n",
    "    CROPPED_FILE_PATH = get_project_root().joinpath('outputs/cropped/')\n",
    "    FEATURE_FILE_PATH = get_project_root().joinpath('outputs/features/')\n",
    "    FIGURE_FILE_PATH = get_project_root().joinpath('outputs/figures/')\n",
    "    LOWER_BOUND = -0.2\n",
    "    #MATLAB_PATH = '/Applications/MATLAB_R2019a.app/bin/matlab'  #Replace with your MATLAB path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Epoch(object):\n",
    "    DURATION = 30  # seconds\n",
    "    def __init__(self, timestamp, index):\n",
    "        self.timestamp = timestamp\n",
    "        self.index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSGService(object):\n",
    "    @staticmethod\n",
    "    def crop(psg_raw_collection, interval):\n",
    "        subject_id = psg_raw_collection.subject_id\n",
    "\n",
    "        stage_items = []\n",
    "        for stage_item in psg_raw_collection.data:\n",
    "            timestamp = stage_item.epoch.timestamp\n",
    "            if interval.start_time <= timestamp < interval.end_time:\n",
    "                stage_items.append(stage_item)\n",
    "\n",
    "        return PSGRawDataCollection(subject_id=subject_id, data=stage_items)\n",
    "    @staticmethod\n",
    "    def write(psg_raw_data_collection):\n",
    "        data_array = []\n",
    "        for index in range(len(psg_raw_data_collection.data)):\n",
    "            stage_item = psg_raw_data_collection.data[index]\n",
    "            data_array.append([stage_item.epoch.timestamp, stage_item.stage.value])\n",
    "        np_psg_array = np.array(data_array)\n",
    "        psg_output_path = Constants.CROPPED_FILE_PATH.joinpath(psg_raw_data_collection.subject_id + \"_cleaned_psg.out\")\n",
    "        np.savetxt(psg_output_path, np_psg_array, fmt='%f')\n",
    "    @staticmethod\n",
    "    def load_cropped_array(subject_id):\n",
    "        cropped_psg_path = Constants.CROPPED_FILE_PATH.joinpath(subject_id + \"_cleaned_psg.out\")\n",
    "        return pd.read_csv(str(cropped_psg_path), delimiter=' ').values\n",
    "    @staticmethod\n",
    "    def load_cropped(subject_id):\n",
    "        cropped_array = PSGService.load_cropped_array(subject_id)\n",
    "        stage_items = []\n",
    "\n",
    "        for row in range(np.shape(cropped_array)[0]):\n",
    "            value = cropped_array[row, 1]\n",
    "            stage_items.append(StageItem(epoch=Epoch(timestamp=cropped_array[row, 0], index=row),\n",
    "                                         stage=PSGConverter.get_label_from_int(value)))\n",
    "\n",
    "        return PSGRawDataCollection(subject_id=subject_id, data=stage_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MotionService(object):\n",
    "    @staticmethod\n",
    "    def load(motion_file, delimiter=' '):\n",
    "        motion_array = pd.read_csv(str(motion_file), delimiter=delimiter).values\n",
    "        return motion_array\n",
    "    @staticmethod\n",
    "    def load_cropped(subject_id):\n",
    "        cropped_motion_path = MotionService.get_cropped_file_path(subject_id)\n",
    "        motion_array = MotionService.load(cropped_motion_path)\n",
    "        return MotionCollection(subject_id=subject_id, data=motion_array)\n",
    "    @staticmethod\n",
    "    def crop(motion_collection, interval):\n",
    "        subject_id = motion_collection.subject_id\n",
    "        timestamps = motion_collection.timestamps\n",
    "        valid_indices = ((timestamps >= interval.start_time)\n",
    "                         & (timestamps < interval.end_time)).nonzero()[0]\n",
    "\n",
    "        cropped_data = motion_collection.data[valid_indices, :]\n",
    "        return MotionCollection(subject_id=subject_id, data=cropped_data)\n",
    "    @staticmethod\n",
    "    def write(motion_collection):\n",
    "        motion_output_path = MotionService.get_cropped_file_path(motion_collection.subject_id)\n",
    "        np.savetxt(motion_output_path, motion_collection.data, fmt='%f')\n",
    "    @staticmethod\n",
    "    def get_cropped_file_path(subject_id):\n",
    "        return Constants.CROPPED_FILE_PATH.joinpath(subject_id + \"_cleaned_motion.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataProcessor:\n",
    "    BASE_FILE_PATH = get_project_root().joinpath('outputs/cropped/')\n",
    "\n",
    "    @staticmethod\n",
    "    def get_valid_epochs(subject_id):\n",
    "        psg_collection = PSGService.load_cropped(subject_id)\n",
    "        motion_collection = MotionService.load_cropped(subject_id)\n",
    "        \n",
    "        start_time = psg_collection.data[0].epoch.timestamp\n",
    "        motion_epoch_dictionary = RawDataProcessor.get_valid_epoch_dictionary(motion_collection.timestamps, start_time)\n",
    "        valid_epochs = []\n",
    "        for stage_item in psg_collection.data:\n",
    "            epoch = stage_item.epoch\n",
    "            if epoch.timestamp in motion_epoch_dictionary and stage_item.stage != SleepStage.unscored:\n",
    "                valid_epochs.append(epoch)\n",
    "        return valid_epochs\n",
    "\n",
    "    @staticmethod\n",
    "    def get_valid_epoch_dictionary(timestamps, start_time):\n",
    "        epoch_dictionary = {}\n",
    "\n",
    "        for ind in range(np.shape(timestamps)[0]):\n",
    "            time = timestamps[ind]\n",
    "            floored_timestamp = time - np.mod(time - start_time, Epoch.DURATION)\n",
    "\n",
    "            epoch_dictionary[floored_timestamp] = True\n",
    "\n",
    "        return epoch_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSGLabelService(object):\n",
    "    @staticmethod\n",
    "    def load(subject_id):\n",
    "        psg_label_path = PSGLabelService.get_path(subject_id)\n",
    "        feature = pd.read_csv(str(psg_label_path)).values\n",
    "        return feature\n",
    "\n",
    "    @staticmethod\n",
    "    def get_path(subject_id):\n",
    "        return Constants.FEATURE_FILE_PATH.joinpath(subject_id + '_psg_labels.out')\n",
    "\n",
    "    @staticmethod\n",
    "    def build(subject_id, valid_epochs):\n",
    "        psg_array = PSGService.load_cropped_array(subject_id)\n",
    "        labels = []\n",
    "        for epoch in valid_epochs:\n",
    "            value = np.interp(epoch.timestamp, psg_array[:, 0], psg_array[:, 1])\n",
    "            labels.append(value)\n",
    "        return np.array(labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def write(subject_id, labels):\n",
    "        psg_labels_path = PSGLabelService.get_path(subject_id)\n",
    "        np.savetxt(psg_labels_path, labels, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeBasedFeatureService(object):\n",
    "    @staticmethod\n",
    "    def load_time(subject_id):\n",
    "        feature_path = TimeBasedFeatureService.get_path_for_time(subject_id)\n",
    "        feature = pd.read_csv(str(feature_path)).values\n",
    "        return feature\n",
    "\n",
    "    @staticmethod\n",
    "    def get_path_for_time(subject_id):\n",
    "        return Constants.FEATURE_FILE_PATH.joinpath(subject_id + '_time_feature.out')\n",
    "\n",
    "    @staticmethod\n",
    "    def write_time(subject_id, feature):\n",
    "        feature_path = TimeBasedFeatureService.get_path_for_time(subject_id)\n",
    "        np.savetxt(feature_path, feature, fmt='%f')\n",
    "\n",
    "    @staticmethod\n",
    "    def load_circadian_model(subject_id):\n",
    "        feature_path = TimeBasedFeatureService.get_path_for_circadian_model(subject_id)\n",
    "        feature = pd.read_csv(str(feature_path), delimiter=' ').values\n",
    "        return feature\n",
    "\n",
    "    @staticmethod\n",
    "    def get_path_for_circadian_model(subject_id):\n",
    "        return Constants.FEATURE_FILE_PATH.joinpath(subject_id + '_circadian_feature.out')\n",
    "\n",
    "    @staticmethod\n",
    "    def write_circadian_model(subject_id, feature):\n",
    "        feature_path = TimeBasedFeatureService.get_path_for_circadian_model(subject_id)\n",
    "        np.savetxt(feature_path, feature, fmt='%f')\n",
    "\n",
    "    @staticmethod\n",
    "    def load_cosine(subject_id):\n",
    "        feature_path = TimeBasedFeatureService.get_path_for_cosine(subject_id)\n",
    "        feature = pd.read_csv(str(feature_path)).values\n",
    "        return feature\n",
    "\n",
    "    @staticmethod\n",
    "    def get_path_for_cosine(subject_id):\n",
    "        return Constants.FEATURE_FILE_PATH.joinpath(subject_id + '_cosine_feature.out')\n",
    "\n",
    "    @staticmethod\n",
    "    def write_cosine(subject_id, feature):\n",
    "        feature_path = TimeBasedFeatureService.get_path_for_cosine(subject_id)\n",
    "        np.savetxt(feature_path, feature, fmt='%f')\n",
    "\n",
    "    @staticmethod\n",
    "    def build_time(valid_epochs):\n",
    "        features = []\n",
    "        first_timestamp = valid_epochs[0].timestamp\n",
    "        for epoch in valid_epochs:\n",
    "            value = epoch.timestamp - first_timestamp\n",
    "\n",
    "            value = value / 3600.0  # Changing units to hours improves performance\n",
    "\n",
    "            features.append(value)\n",
    "        return np.array(features)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_circadian_model(subject_id, valid_epochs):\n",
    "        circadian_file = utils.get_project_root().joinpath('data/circadian_predictions/' + subject_id +\n",
    "                                                           '_clock_proxy.txt')\n",
    "        if circadian_file.is_file():\n",
    "            circadian_model = pd.read_csv(str(circadian_file), delimiter=',').values\n",
    "\n",
    "            return TimeBasedFeatureService.build_circadian_model_from_raw(circadian_model, valid_epochs)\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_proxy(time):\n",
    "        sleep_drive_cosine_shift = 5\n",
    "        return -1 * np.math.cos((time - sleep_drive_cosine_shift * Constants.SECONDS_PER_HOUR) *\n",
    "                                2 * np.math.pi / Constants.SECONDS_PER_DAY)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_cosine(valid_epochs):\n",
    "        features = []\n",
    "        first_value = TimeBasedFeatureService.cosine_proxy(0)\n",
    "        first_timestamp = valid_epochs[0].timestamp\n",
    "\n",
    "        for epoch in valid_epochs:\n",
    "            value = TimeBasedFeatureService.cosine_proxy(epoch.timestamp - first_timestamp)\n",
    "            normalized_value = value\n",
    "            features.append(normalized_value)\n",
    "\n",
    "        return np.array(features)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_circadian_model_from_raw(circadian_model, valid_epochs):\n",
    "        features = []\n",
    "\n",
    "        first_inactive_epoch = valid_epochs[0]\n",
    "        first_value = np.interp(first_inactive_epoch.timestamp, circadian_model[:, 0], circadian_model[:, 1])\n",
    "\n",
    "        for epoch in valid_epochs:\n",
    "            time = epoch.timestamp\n",
    "            value = np.interp(time, circadian_model[:, 0], circadian_model[:, 1])\n",
    "            normalized_value = (value - first_value) / (np.amin((circadian_model[:, 1] - first_value)))\n",
    "\n",
    "            if normalized_value < Constants.LOWER_BOUND:\n",
    "                normalized_value = Constants.LOWER_BOUND\n",
    "\n",
    "            features.append([normalized_value])\n",
    "\n",
    "        feature_array = np.array(features)\n",
    "\n",
    "        return feature_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureBuilder(object):\n",
    "\n",
    "    @staticmethod\n",
    "    def build(subject_id):\n",
    "        if Constants.VERBOSE:\n",
    "            print(\"Getting valid epochs...\")\n",
    "        valid_epochs = RawDataProcessor.get_valid_epochs(subject_id)\n",
    "\n",
    "        if Constants.VERBOSE:\n",
    "            print(\"Building features...\")\n",
    "        FeatureBuilder.build_labels(subject_id, valid_epochs)\n",
    "        FeatureBuilder.build_from_time(subject_id, valid_epochs)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_labels(subject_id, valid_epochs):\n",
    "        psg_labels = PSGLabelService.build(subject_id, valid_epochs)\n",
    "        PSGLabelService.write(subject_id, psg_labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_from_time(subject_id, valid_epochs):\n",
    "\n",
    "        # circadian_feature = TimeBasedFeatureService.build_circadian_model(subject_id, valid_epochs)\n",
    "        cosine_feature = TimeBasedFeatureService.build_cosine(valid_epochs)\n",
    "        time_feature = TimeBasedFeatureService.build_time(valid_epochs)\n",
    "\n",
    "        # TimeBasedFeatureService.write_circadian_model(subject_id, circadian_feature)\n",
    "        TimeBasedFeatureService.write_cosine(subject_id, cosine_feature)\n",
    "        TimeBasedFeatureService.write_time(subject_id, time_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3509524 Cropped data로 변환 시작\n",
      "5132496 Cropped data로 변환 시작\n",
      "1066528 Cropped data로 변환 시작\n",
      "5498603 Cropped data로 변환 시작\n",
      "2638030 Cropped data로 변환 시작\n",
      "2598705 Cropped data로 변환 시작\n",
      "5383425 Cropped data로 변환 시작\n",
      "1455390 Cropped data로 변환 시작\n",
      "4018081 Cropped data로 변환 시작\n",
      "9961348 Cropped data로 변환 시작\n",
      "1449548 Cropped data로 변환 시작\n",
      "8258170 Cropped data로 변환 시작\n",
      "781756 Cropped data로 변환 시작\n",
      "9106476 Cropped data로 변환 시작\n",
      "8686948 Cropped data로 변환 시작\n",
      "8530312 Cropped data로 변환 시작\n",
      "3997827 Cropped data로 변환 시작\n",
      "4314139 Cropped data로 변환 시작\n",
      "1818471 Cropped data로 변환 시작\n",
      "4426783 Cropped data로 변환 시작\n",
      "8173033 Cropped data로 변환 시작\n",
      "7749105 Cropped data로 변환 시작\n",
      "5797046 Cropped data로 변환 시작\n",
      "759667 Cropped data로 변환 시작\n",
      "8000685 Cropped data로 변환 시작\n",
      "6220552 Cropped data로 변환 시작\n",
      "844359 Cropped data로 변환 시작\n",
      "9618981 Cropped data로 변환 시작\n",
      "1360686 Cropped data로 변환 시작\n",
      "46343 Cropped data로 변환 시작\n",
      "8692923 Cropped data로 변환 시작\n",
      "실행 시간 5.489970497290293분 걸림\n"
     ]
    }
   ],
   "source": [
    "subject_ids = get_all_subject_ids()\n",
    "\n",
    "start_time = time.time()\n",
    "for subject in subject_ids:\n",
    "    print(str(subject) + \" Cropped data로 변환 시작\")\n",
    "    crop_all(str(subject))\n",
    "    \n",
    "for subject in subject_ids:\n",
    "    FeatureBuilder.build(str(subject))\n",
    "end_time = time.time()\n",
    "print(\"실행 시간 \" + str((end_time - start_time) / 60) + \"분 걸림\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "#from source import utils\n",
    "\n",
    "\n",
    "class DataPlotBuilder(object):\n",
    "    @staticmethod\n",
    "    def timestamp_to_string(ts):\n",
    "        return time.strftime('%H:%M:%S', time.localtime(ts))\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_labels_for_hypnogram(labels):\n",
    "        processed_labels = np.array([])\n",
    "\n",
    "        for epoch in labels:\n",
    "            if epoch == -1:\n",
    "                processed_labels = np.append(processed_labels, 0)\n",
    "            elif epoch == 5:\n",
    "                processed_labels = np.append(processed_labels, 1)\n",
    "            else:\n",
    "                processed_labels = np.append(processed_labels, -1 * epoch)\n",
    "\n",
    "        return processed_labels\n",
    "\n",
    "    @staticmethod\n",
    "    def tidy_data_plot(x_min, x_max, dt, ax):\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(True)\n",
    "        ax.spines['left'].set_visible(True)\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        xticks = np.arange(x_min, x_max, dt)\n",
    "        plt.xticks(xticks)\n",
    "        labels = []\n",
    "        for xt in xticks:\n",
    "            labels.append(DataPlotBuilder.timestamp_to_string(xt))\n",
    "        ax.set_xticklabels(labels)\n",
    "        plt.xlim(x_min, x_max)\n",
    "\n",
    "    @staticmethod\n",
    "    def make_data_demo(subject_id=\"16\", snippet=False):\n",
    "        motion_color = [0.3, 0.2, 0.8]\n",
    "        psg_color = [0.1, 0.7, 0.1]\n",
    "        font_size = 16\n",
    "        font_name = \"Arial\"\n",
    "\n",
    "        data_path = str(Constants.CROPPED_FILE_PATH) + '/'\n",
    "        output_path = str(Constants.FIGURE_FILE_PATH) + '/'\n",
    "\n",
    "        if snippet is False:\n",
    "            fig = plt.figure(figsize=(10, 12))\n",
    "        else:\n",
    "            fig = plt.figure(figsize=(3, 12))\n",
    "\n",
    "        num_v_plots = 5\n",
    "        fig.patch.set_facecolor('white')\n",
    "\n",
    "        if (os.path.isfile(data_path + subject_id + '_cleaned_motion.out') and os.path.isfile(data_path + subject_id + '_cleaned_psg.out') and os.stat(data_path + subject_id + '_cleaned_motion.out').st_size > 0):\n",
    "\n",
    "            motion = np.genfromtxt(data_path + subject_id + '_cleaned_motion.out', delimiter=' ')\n",
    "            scores = np.genfromtxt(data_path + subject_id + '_cleaned_psg.out', delimiter=' ')\n",
    "\n",
    "            min_time = min(scores[:, 0])\n",
    "            max_time = max(scores[:, 0])\n",
    "            dt = 60 * 60\n",
    "\n",
    "            sample_point_fraction = 0.92\n",
    "\n",
    "            sample_point = sample_point_fraction * (max_time - min_time) + min_time\n",
    "            window_size = 10\n",
    "            if snippet:\n",
    "                min_time = sample_point\n",
    "                max_time = sample_point + window_size\n",
    "\n",
    "            ax = plt.subplot(num_v_plots, 1, 1)\n",
    "            ax.plot(motion[:, 0], motion[:, 1], color=motion_color)\n",
    "            ax.plot(motion[:, 0], motion[:, 2], color=[0.4, 0.2, 0.7])\n",
    "            ax.plot(motion[:, 0], motion[:, 3], color=[0.5, 0.2, 0.6])\n",
    "            plt.ylabel('Motion (g)', fontsize=font_size, fontname=font_name)\n",
    "            DataPlotBuilder.tidy_data_plot(min_time, max_time, dt, ax)\n",
    "\n",
    "            if snippet:\n",
    "                ax.spines['bottom'].set_visible(True)\n",
    "                ax.spines['left'].set_visible(True)\n",
    "                ax.spines['top'].set_visible(True)\n",
    "                ax.spines['right'].set_visible(True)\n",
    "\n",
    "                ax.yaxis.label.set_visible(False)\n",
    "\n",
    "                inds = np.intersect1d(np.where(motion[:, 0] > sample_point)[0],\n",
    "                                      np.where(motion[:, 0] <= sample_point + window_size)[0])\n",
    "                y_min = np.amin(motion[inds, 1:3])\n",
    "                plt.ylim(y_min - 0.005, y_min + 0.025)\n",
    "\n",
    "                # Get rid of the ticks\n",
    "                ax.set_xticks([])\n",
    "                ax.yaxis.set_ticks_position(\"right\")\n",
    "\n",
    "                plt.ylabel('')\n",
    "                plt.xlabel(str(window_size) + ' sec window', fontsize=font_size, fontname=font_name)\n",
    "            else:\n",
    "                y_min = -3.2\n",
    "                y_max = 2.5\n",
    "                plt.ylim(y_min, y_max)\n",
    "                current_axis = plt.gca()\n",
    "                current_axis.add_patch(\n",
    "                    Rectangle((sample_point, y_min), window_size, y_max - y_min, alpha=0.7, facecolor=\"gray\"))\n",
    "\n",
    "\n",
    "            ax = plt.subplot(num_v_plots, 1, 2)\n",
    "            relabeled_scores = DataPlotBuilder.convert_labels_for_hypnogram(scores[:, 1])\n",
    "            ax.step(scores[:, 0], relabeled_scores, color=psg_color)\n",
    "            plt.ylabel('Stage', fontsize=font_size, fontname=font_name)\n",
    "            plt.xlabel('Time', fontsize=font_size, fontname=font_name)\n",
    "            DataPlotBuilder.tidy_data_plot(min_time, max_time, dt, ax)\n",
    "            ax.set_yticks([-4, -3, -2, -1, 0, 1])\n",
    "            ax.set_yticklabels(['N4', 'N3', 'N2', 'N1', 'Wake', 'REM'])\n",
    "\n",
    "            if snippet:\n",
    "                plt.axis('off')\n",
    "                plt.ylim(5, 5)\n",
    "            else:\n",
    "                plt.ylim(-5, 2)\n",
    "\n",
    "            if not snippet:\n",
    "                plt.savefig(output_path + 'data_validation_' + subject_id + '.png', bbox_inches='tight', pad_inches=0.1, dpi=300)\n",
    "            else:\n",
    "                plt.savefig(output_path + 'data_validation_zoom_' + subject_id + '.png', bbox_inches='tight',pad_inches=0.1, dpi=300)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = get_all_subject_ids()\n",
    "for subject in subject_ids:\n",
    "    DataPlotBuilder.make_data_demo(subject, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
